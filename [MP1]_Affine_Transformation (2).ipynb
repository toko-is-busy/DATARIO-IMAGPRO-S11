{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lx3q29NZnc4H"
   },
   "source": [
    "# Machine Problem 1: Affine Transformations\n",
    "\n",
    "## Group 4 Members:\n",
    "1.   ARCETA, ALTHEA ZYRIE MANUEL\n",
    "2.   DATARIO, YASMIN AUDREY TUTANES\n",
    "3.   TAN, JOSE TRISTAN TURTOZA\n",
    "4.   TUMALAD, SHAWNE MICHAEL QUIAPOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25LhaPsOnmMT"
   },
   "source": [
    "\n",
    "## Description of the Project\n",
    "The goal of the machine problem is to apply the concepts of affine transformations, specifically using geometric transformations. You are to submit two files for this activity: (1) a Jupyter notebook containing the solutions to the action items. Ensure you provide comments, discussions, and proper section divisions for your code. Please also include your answer to the Guide Questions in the Jupyter Notebook; (2) a PDF version of your Jupyter Notebook. You can provide a link to your submission resources or a zip file. The instructor will run it on their local machine, so make sure the codes and files are accessible and functional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJb7uurUUNyQ"
   },
   "source": [
    "#1. Data Formatting\n",
    "- Reshape the images to (100,100,3)\n",
    "- Save the transformed images as JPEG files in a separate directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4719,
     "status": "ok",
     "timestamp": 1741958868620,
     "user": {
      "displayName": "Jose Tristan Tan",
      "userId": "15497401588657745153"
     },
     "user_tz": -480
    },
    "id": "8STkuC3t04Fo",
    "outputId": "41ed7211-2cda-4e17-c4d8-1a679763aa88"
   },
   "outputs": [],
   "source": [
    "#Uncomment this cell if may error sa import packages\n",
    "#Install OpenCV\n",
    "!pip install opencv-python-headless\n",
    "\n",
    "# Install numpy (if not already installed)\n",
    "!pip install numpy\n",
    "\n",
    "# Install Pillow (for displaying images in Jupyter)\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neBeyRu-YwLb"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTQ_uEWnYpEz"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UfKV_rNUfoZ"
   },
   "source": [
    "### Getting & Viewing the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1699,
     "status": "ok",
     "timestamp": 1741958874425,
     "user": {
      "displayName": "Jose Tristan Tan",
      "userId": "15497401588657745153"
     },
     "user_tz": -480
    },
    "id": "kAMiYQYDSdyT",
    "outputId": "fb79800d-61d7-46d3-96b4-bc6fa23e511c"
   },
   "outputs": [],
   "source": [
    "url = \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0001.jpg\"\n",
    "resp = requests.get(url)\n",
    "img_array = np.asarray(bytearray(resp.content), dtype=np.uint8)\n",
    "img1 = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Convert BGR to RGB for correct display in Colab\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "display(Image.fromarray(img1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2183,
     "status": "ok",
     "timestamp": 1741958887844,
     "user": {
      "displayName": "Jose Tristan Tan",
      "userId": "15497401588657745153"
     },
     "user_tz": -480
    },
    "id": "5PxBXiQZTB_q",
    "outputId": "0d0ac719-e533-4339-cd07-cec3fa1036f2"
   },
   "outputs": [],
   "source": [
    "url = \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0002.jpg\"\n",
    "resp = requests.get(url)\n",
    "img_array = np.asarray(bytearray(resp.content), dtype=np.uint8)\n",
    "img2 = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Convert BGR to RGB for correct display in Colab\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "display(Image.fromarray(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1994,
     "status": "ok",
     "timestamp": 1741958899574,
     "user": {
      "displayName": "Jose Tristan Tan",
      "userId": "15497401588657745153"
     },
     "user_tz": -480
    },
    "id": "QiB_DvgkTWX7",
    "outputId": "0feee3a6-1689-4cf7-8938-992a1f7f9660"
   },
   "outputs": [],
   "source": [
    "url = \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0003.jpg\"\n",
    "resp = requests.get(url)\n",
    "img_array = np.asarray(bytearray(resp.content), dtype=np.uint8)\n",
    "img3 = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Convert BGR to RGB for correct display in Colab\n",
    "img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)\n",
    "display(Image.fromarray(img3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3135,
     "status": "ok",
     "timestamp": 1741958902870,
     "user": {
      "displayName": "Jose Tristan Tan",
      "userId": "15497401588657745153"
     },
     "user_tz": -480
    },
    "id": "MsCIRJ8TTcLy",
    "outputId": "1a9a5dc7-884c-4f7f-d8d2-d07b7adcff21"
   },
   "outputs": [],
   "source": [
    "url = \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0007.jpg\"\n",
    "resp = requests.get(url)\n",
    "img_array = np.asarray(bytearray(resp.content), dtype=np.uint8)\n",
    "img7 = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Convert BGR to RGB for correct display in Colab\n",
    "img7 = cv2.cvtColor(img7, cv2.COLOR_BGR2RGB)\n",
    "display(Image.fromarray(img7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1967,
     "status": "ok",
     "timestamp": 1741958906942,
     "user": {
      "displayName": "Jose Tristan Tan",
      "userId": "15497401588657745153"
     },
     "user_tz": -480
    },
    "id": "vH-2m4lYTgpY",
    "outputId": "e6753359-6887-45ef-a3d1-49385c74440a"
   },
   "outputs": [],
   "source": [
    "url = \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0008.jpg\"\n",
    "resp = requests.get(url)\n",
    "img_array = np.asarray(bytearray(resp.content), dtype=np.uint8)\n",
    "img8 = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Convert BGR to RGB for correct display in Colab\n",
    "img8 = cv2.cvtColor(img8, cv2.COLOR_BGR2RGB)\n",
    "display(Image.fromarray(img8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1451,
     "status": "ok",
     "timestamp": 1741958908934,
     "user": {
      "displayName": "Jose Tristan Tan",
      "userId": "15497401588657745153"
     },
     "user_tz": -480
    },
    "id": "PpMvxTiuTuX_",
    "outputId": "4abe6d02-920d-4976-de2d-c3dcf86287df"
   },
   "outputs": [],
   "source": [
    "url = \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0009.jpg\"\n",
    "resp = requests.get(url)\n",
    "img_array = np.asarray(bytearray(resp.content), dtype=np.uint8)\n",
    "img9 = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Convert BGR to RGB for correct display in Colab\n",
    "img9 = cv2.cvtColor(img9, cv2.COLOR_BGR2RGB)\n",
    "display(Image.fromarray(img9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1136,
     "status": "ok",
     "timestamp": 1741958910883,
     "user": {
      "displayName": "Jose Tristan Tan",
      "userId": "15497401588657745153"
     },
     "user_tz": -480
    },
    "id": "4V3aW0s2TzD0",
    "outputId": "19f4d911-e3d0-4913-ccf4-03e885611943"
   },
   "outputs": [],
   "source": [
    "url = \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0010.jpg\"\n",
    "resp = requests.get(url)\n",
    "img_array = np.asarray(bytearray(resp.content), dtype=np.uint8)\n",
    "img10 = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Convert BGR to RGB for correct display in Colab\n",
    "img10 = cv2.cvtColor(img10, cv2.COLOR_BGR2RGB)\n",
    "display(Image.fromarray(img10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2539,
     "status": "ok",
     "timestamp": 1741958914371,
     "user": {
      "displayName": "Jose Tristan Tan",
      "userId": "15497401588657745153"
     },
     "user_tz": -480
    },
    "id": "j2opvIWZT3cF",
    "outputId": "18351360-1669-42b9-fa0d-97c06dee8348"
   },
   "outputs": [],
   "source": [
    "url = \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0011.jpg\"\n",
    "resp = requests.get(url)\n",
    "img_array = np.asarray(bytearray(resp.content), dtype=np.uint8)\n",
    "img11 = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Convert BGR to RGB for correct display in Colab\n",
    "img11 = cv2.cvtColor(img11, cv2.COLOR_BGR2RGB)\n",
    "display(Image.fromarray(img11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1269,
     "status": "ok",
     "timestamp": 1741958915640,
     "user": {
      "displayName": "Jose Tristan Tan",
      "userId": "15497401588657745153"
     },
     "user_tz": -480
    },
    "id": "nM1b7yaeT82r",
    "outputId": "50385115-07f0-4dab-8e4f-e8a12130457a"
   },
   "outputs": [],
   "source": [
    "url = \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0020.jpg\"\n",
    "resp = requests.get(url)\n",
    "img_array = np.asarray(bytearray(resp.content), dtype=np.uint8)\n",
    "img20 = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Convert BGR to RGB for correct display in Colab\n",
    "img20 = cv2.cvtColor(img20, cv2.COLOR_BGR2RGB)\n",
    "display(Image.fromarray(img20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2598,
     "status": "ok",
     "timestamp": 1741958918239,
     "user": {
      "displayName": "Jose Tristan Tan",
      "userId": "15497401588657745153"
     },
     "user_tz": -480
    },
    "id": "tDsMgl_uUDYp",
    "outputId": "3d2670bf-1552-4c37-9edd-e122562e4465"
   },
   "outputs": [],
   "source": [
    "url = \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0030.jpg\"\n",
    "resp = requests.get(url)\n",
    "img_array = np.asarray(bytearray(resp.content), dtype=np.uint8)\n",
    "img30 = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Convert BGR to RGB for correct display in Colab\n",
    "img30 = cv2.cvtColor(img30, cv2.COLOR_BGR2RGB)\n",
    "display(Image.fromarray(img30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qm13dXXgVrQW"
   },
   "outputs": [],
   "source": [
    "arrayNumber = [1, 2, 3, 7, 8, 9, 10, 11, 20, 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OIeC8AzVDmD"
   },
   "source": [
    "### Reshape the image to (100, 100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1934,
     "status": "ok",
     "timestamp": 1741958925238,
     "user": {
      "displayName": "Jose Tristan Tan",
      "userId": "15497401588657745153"
     },
     "user_tz": -480
    },
    "id": "V5TjqYCDUJeW",
    "outputId": "49b60065-ceeb-4feb-ef7d-bfed74bc1c48"
   },
   "outputs": [],
   "source": [
    "# List of image URLs from GitHub (Replace these with your actual image links)\n",
    "image_urls = [\n",
    "    \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0001.jpg\",\n",
    "    \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0002.jpg\",\n",
    "    \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0003.jpg\",\n",
    "    \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0007.jpg\",\n",
    "    \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0008.jpg\",\n",
    "    \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0009.jpg\",\n",
    "    \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0010.jpg\",\n",
    "    \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0011.jpg\",\n",
    "    \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0020.jpg\",\n",
    "    \"https://github.com/dyjdlopez/fund-dip/raw/main/media/dataset2/0030.jpg\",\n",
    "]\n",
    "\n",
    "img_ds = []\n",
    "\n",
    "# Create a folder to save resized images\n",
    "os.makedirs(\"resized_images\", exist_ok=True)\n",
    "\n",
    "# Process each image\n",
    "for i, url in enumerate(image_urls):\n",
    "    response = requests.get(url)\n",
    "    img_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Resize to (100, 100)\n",
    "    img_resized = cv2.resize(img, (100, 100))\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    img_resized = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
    "    img_ds.append(img_resized)\n",
    "\n",
    "    # Saving to JPEG\n",
    "    img_pil = Image.fromarray(img_resized)\n",
    "    img_pil.save(f\"resized_images/img_{i+1}.jpg\", \"JPEG\")\n",
    "\n",
    "    print(f\"Saved: resized_images/img_{i+1}.jpg\")\n",
    "\n",
    "print(\"All images resized and saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQQAhHQTZPWu"
   },
   "source": [
    "# 2. Data Augmentation\n",
    "Given the previous dataset:\n",
    "- Create individual parametrized functions that can:\n",
    "  - Randomly put a black patch over a portion of the image\n",
    "  - Shift an image sidewards or upwards.\n",
    "  - Rotate an image either for 30 or 60 degrees.\n",
    "  - Flip an image either vertically or horizontally.\n",
    "- Produce a new augmented dataset with at least 100 images (original images included) using the functions made in the previous action item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbOzU5VlXc1J"
   },
   "outputs": [],
   "source": [
    "def add_black_patch(image, patch_size=(30, 30)):\n",
    "    h, w, _ = image.shape\n",
    "    x = random.randint(0, w - patch_size[0])\n",
    "    y = random.randint(0, h - patch_size[1])\n",
    "    image[y:y+patch_size[1], x:x+patch_size[0]] = (0, 0, 0)  # Draw black patch\n",
    "    return image\n",
    "\n",
    "def shift_image(image, shift_value=20, mode = None):\n",
    "    h, w, _ = image.shape  # Get image dimensions\n",
    "    if mode is None:\n",
    "        mode = random.choice([0, 1, 2, 3])\n",
    "\n",
    "    if mode == 0:  # Up\n",
    "        M = np.float32([[1, 0, 0], [0, 1, -shift_value]])\n",
    "    elif mode == 1:  # Down\n",
    "        M = np.float32([[1, 0, 0], [0, 1, shift_value]])\n",
    "    elif mode == 2:  # Left\n",
    "        M = np.float32([[1, 0, -shift_value], [0, 1, 0]])\n",
    "    elif mode == 3:  # Right\n",
    "        M = np.float32([[1, 0, shift_value], [0, 1, 0]])\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be 0 (Up), 1 (Down), 2 (Left), or 3 (Right)\")\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "    shifted = cv2.warpAffine(image, M, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))\n",
    "\n",
    "    return shifted\n",
    "\n",
    "def rotate_image(image, angle = None):\n",
    "\n",
    "    if angle is None:\n",
    "        angle = random.choice([30, 60])\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle=angle, scale=1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))\n",
    "    return rotated\n",
    "\n",
    "def flip_image(image, mode=None):\n",
    "    \"\"\"\n",
    "    mode = 0 -> Vertical flip\n",
    "    mode = 1 -> Horizontal flip\n",
    "    \"\"\"\n",
    "    if mode is None:\n",
    "        mode = random.choice([0, 1])\n",
    "\n",
    "    return cv2.flip(image, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39i7bIM9h7iT"
   },
   "outputs": [],
   "source": [
    "def augment_dataset(img_ds, output_dir):\n",
    "    augmented_images = []\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
    "    count = 0\n",
    "\n",
    "    for i, img in enumerate(img_ds):\n",
    "        if count >= 100:\n",
    "            break\n",
    "\n",
    "        # Resize to 100x100 before augmentation\n",
    "        img_resized = cv2.resize(img, (100, 100))\n",
    "\n",
    "        # Random values\n",
    "        a = random.randint(5, 50)\n",
    "        patch_size = (a, a)\n",
    "        shift_value = random.randint(10, 50)\n",
    "        a = random.randint(5, 50)\n",
    "        patch_size1 = (a, a)\n",
    "        shift_value1 = random.randint(10, 50)\n",
    "\n",
    "        # Apply all 4 augmentations and save each\n",
    "        augmented = [\n",
    "            img_resized,  # Original\n",
    "            add_black_patch(img_resized, patch_size),\n",
    "            add_black_patch(img_resized, patch_size1),\n",
    "            shift_image(img_resized, shift_value, 0),\n",
    "            shift_image(img_resized, shift_value1, 1),\n",
    "            shift_image(img_resized, shift_value, 2),\n",
    "            shift_image(img_resized, shift_value1, 3),\n",
    "            rotate_image(img_resized, 30),\n",
    "            rotate_image(img_resized, 60),\n",
    "            flip_image(img_resized, 0),\n",
    "            flip_image(img_resized, 1)\n",
    "        ]\n",
    "\n",
    "        for aug_img in augmented:\n",
    "            filename = os.path.join(output_dir, f\"aug_{count}.jpg\")\n",
    "            cv2.imwrite(filename, aug_img)\n",
    "            augmented_images.append(aug_img)\n",
    "            count += 1\n",
    "\n",
    "            # Stop if we reach 100 images\n",
    "            if count >= 100:\n",
    "                break\n",
    "\n",
    "    print(f\"Generated {count} augmented images and saved to {output_dir}.\")\n",
    "    return np.array(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1741959045821,
     "user": {
      "displayName": "Jose Tristan Tan",
      "userId": "15497401588657745153"
     },
     "user_tz": -480
    },
    "id": "5GZZ8_qSelgG",
    "outputId": "8b3134c6-4bd8-4297-b838-e4e3de8158d9"
   },
   "outputs": [],
   "source": [
    "output_dir = \"augmented_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create directory\n",
    "\n",
    "# Run augmentation\n",
    "augmented_imgs = augment_dataset(img_ds, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_hAdBFmi6ov"
   },
   "source": [
    "## Guide Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzcVDlCl04Fs"
   },
   "source": [
    "1. Define Data Augmentation and discuss its importance and the importance of understanding digital image processing for such an activity.\n",
    "\n",
    "Data augmentation is a technique that is used to artifically increase the size of a dataset through the creation of modified versions of existing items in the dataset. For images, this involves transformations such as rotation, flip, zoom, color adjustment, etc. This technique helps train models on a wider range of scenarios without needing additional data collection.\n",
    "\n",
    "One of the main reasons data augmentation is important is that many datasets are limited in size. If a model sees only a narrow set of examples during training, it can easily become “too good” at recognizing those specific examples, and thus, failing when faced with new or slightly different images. By mixing in augmented versions of the training images, you are teaching the model to notice important patterns while ignoring minor variations in orientation, lighting, or scale. Thus, model generalization is improved since machine learning models need vast amounts of data.\n",
    "\n",
    "Additionally, understanding digital image processing is crucial for applying data augmentation effectively. Even simple transformations such as rotation, flipping, or color adjustments require knowledge of how pixel values shift and are recalculated. Without this, augmented images can become distorted or misaligned, compromising model performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NaF6S-r04Fs"
   },
   "source": [
    "2. What other data augmentation techniques are applicable and not applicable to the dataset you have produced? Why?\n",
    "\n",
    "Here are some applicable techniques:\n",
    "- Adding noise (gaussian, salt-and-pepper, etc), this is applicable since real world images can often be imperfect or noisy.\n",
    "- Zooming (in or out), this is applicable since objects in real world can appear at different scales, which will allow the model to recognize objects at various sizes.\n",
    "- Some color changes (brightness/contrast manipulation), this is applicable since real world images have different lighting, which will allow the model to recognize images in different lighting conditions.\n",
    "\n",
    "Some inapplicable techniques:\n",
    "- Color inversion, this is quite strange and may be confusing to a model.\n",
    "- Extreme rotation (180 degrees), depending on the object this may be unrealistic or confusing especially when the image has a clear up and down.\n",
    "- Heavy distortion/blurring, depending on the intensity, some distortions may be so extreme that the objects in them\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
